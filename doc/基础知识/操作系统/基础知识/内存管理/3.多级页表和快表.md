

# 多级页表和快表  


## 分页机制引发的问题

* 为了提高内存的空间利用率，页应该尽可能小，但是同一个段分成若干页，页越小意味着页表就大了  

* 程序中的逻辑地址，除以页的大小，得到一个页号(页表项)，之后查找页表得到页框号以后，乘以4K得到物理地址;
* 也就是说，32位机器中，用户写的程序逻辑地址空间很大，但页很小，得到的逻辑页号会很多，每个逻辑页号要建立对应的物理页框的关系，页表就会很大
* 32位机器中，程序中的逻辑地址可以有2^32,  4G / 4K = 1M (2^32 / 2^12 = 2 ^ 20) 会有1M大小的页表项，一个页表项一般是4个字节，所以一个进程就需要4M的内存保存页表；
* 实际上，一个进程并不是真的就要用4G这么多逻辑地址  大部分逻辑地址根本用不到

![image](https://user-images.githubusercontent.com/58176267/161534958-6efb178a-80c1-4294-b6f4-38b34e365792.png)

* 如下图，一个进程如果按4G内存，可能需要1M个的页表项，但实际中，不可能每个页表项对应的物理地址都被使用，如下图，页号为2的页表项就没用(代码段分别放到了页框号1,5,6的地方，三个页表项就行)  
![image](https://user-images.githubusercontent.com/58176267/161537090-6f938ea1-a1e0-4627-b4e2-5ca10e027530.png)

## 解决上面问题的第一个思路  

* 用到的逻辑页才有页表项  如上面，只有页号为0 ，1， 3的页表项 
    * 但是页表中的页号不连续，就需要比较、查找，比如页号是3，需要从第一个页表项开始，比较这个页号是不是3，不是就看下一个 O(N)复杂度 （而之前如果用到的没用到的都有的话，需要那个页号，用O(1)时间就可以拿到其对应的页框号）  
    * 当然，一个页号是有序的页表的话，可以用二分查找，O(logN),但是也比较大  

![image](https://user-images.githubusercontent.com/58176267/161539775-881bb71d-1f73-427f-9216-ddb59c404591.png)

## 多级页表  

* 类似于书的章节和每一章节的节目录 
    * 上面这种页表的形式，就是直接将每章节的小目录和它对应的page对应起来  而实际中要找某一小章节目录，一般都是先找它对是哪一大章节，比如知道它在第5章，然后在第五章中查找这个小章节
    * 每一小章节仍然都是连续的，就好比页号仍然是连续的，但是没用到的那些，不需要放到内存中


* 如下图，有2^10个页目录号，可以根据每一个页目录号得到一张页表，每个页表有2^10个页号，根据每个页号，能得到2^10个页,每个页是4K,因此每个页目录号指向的是4M的内存空间(1K乘以4K)  

* **这种设计最厉害的地方在于** ：
    * 1.每一个页目录号都能对应4M的内存空间(一个目录号对应一个含2^10个页号的页表，则内存空间是1K * 4K = 4M)
    * 2.10位表示的也目录号，有1K个， 所以这个进程能处理4G的内存空间
    * 3.如下图例子：这个程序(段)，用了三个目录号，也就是使用了3 * 4 = 12M 的内存空间  而且是可以随意的使用4G空间中任何一页
    * 4.如果不再用多级页表，假设使用了很低位和很高位的地址空间，一是页表的存储需要4M！二是重定位时，由于中间很多没有内容的页号，查找页号需要的时间开销很大 
    * 5.**多级分页以后，还是下面这个例子，需要的目录项花费了4K大小，这是不可避免的(因为为了快速定位，页目录号必须是连续的！，这就类比书的章节是连续的)，一个页表就可以包括4M的物理内存( 也必须是连续的)**，假设这个程序(段)分成三处放在了间隔比较远的页，假设相互之间超过了4M空间，只需要三个页目录项号(**下图中第一个页目录号指向的页表没画出来**)
    * 6. 但是，整个程序只花费了4K * 4 = 16K的内存来记录这个映射关系  远远小于不采用多级分页时的4G  

* 对应逻辑地址，项目录号（0-2^10-1）,直接从项目录表中O(1)时间找到然后获取对应的页表   这张页表也是1K大小(2^10)连续的，所以再根据页号，O(1)时间得到页框号，从而得到物理地址,作为基地址; 再加上偏移地址 就是实际物理地址  

## 多级页表的问题  

* 多级页表提高了空间上的利用率 但是引入了时间上 
    * 如2级，首先得根据页目录号查到对应的页表，然后根据页号查到对应的页框号才得到物理地址，每多一级，就多一次访存(访问内存) 尤其在64位内存上，可能需要更多级页表，每一次重定位的访存次数就会很多，CPU执行程序时，大部分时间花费都是在访存上，因为相比于访问内存，cpu计算速度是快的多的   这个花费可能比不使用多级页表，然后使用不连续的页号使用二分查找效率高很多，但是时间上浪费也挺多  

### TLB---一组相联快速存储 是寄存器  

[TLB和cache的关系](https://blog.csdn.net/yusiguyuan/article/details/39373079)

类似于缓存，建立一张快表，会把进程经常用的页号和对应的页框号记录下来，硬件上面设计好，如果要翻译地址时先通过这个，直接拿到对应的页框号; 当然如果没有，则按多级分页的翻译方式进行重定位，一旦查到了一个对应关系，就把这个对应关系放到快表 

![image](https://user-images.githubusercontent.com/58176267/161551684-dbd9359e-66b7-41f6-b24d-6a476f7944cd.png)

### TLB提高时间效率  

* TLB的命中率越高，时间效率提高就越多  怎样提高命中率？
* 表越大，命中率越高，但不可能无限制增大，因此要有替换策略，太大的TLB，成本就高

![image](https://user-images.githubusercontent.com/58176267/161553965-e5710c19-58c4-4547-adf4-ea0ad0608a5c.png)

* 内存分成了2^20个页，TLB只有64到1024，是很小的，为什么它还能起作用？  
    * 程序的地址访问存在**局部性** ： 比如，程序多体现为顺序，循环结构
    * **空间局部性**    

![image](https://user-images.githubusercontent.com/58176267/161554739-cb13dcfc-7fc2-4243-a794-a8b7ce5bc6af.png)



### 总结  

多级分页 + 快表  既保证了空间利用率，又保证了时间上不会太慢  













